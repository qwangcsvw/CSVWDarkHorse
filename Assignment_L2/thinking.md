# Thinking 1 & 2


## Thinking 1：
>今天讲解了数据采集的方法，在你的工作场景中，是否需要收集数据，都有哪些数据需要收集？（现在是怎样收集的，是否满足你的业务需求）

* 我的工作场景：  
使用有限元工具进行车身结构仿真分析

* 是否需要收集数据，如何收集：  
    - 在进行分析前，需要将设计同事给出的零件号、厚度、材料、重量等信息进行整理
    - 完成分析后，需要对仿真计算结果进行关键值、曲线等信息的提取

* 是否满足你的业务要求
    - 一方面通过现成的有限元前后处理软件可以实现工作需求
    - 另一方面现成的软件存在需要License授权、文件格式多样的问题，难以满足更加灵活的数据处理需求

## Thinking2：
>今天讲解了数据清洗的原则，在你和数据打交道的过程中，你的数据质量如何，是否需要进行数据清洗（包括预测补全）

* 我的数据质量：
    - 前处理通过专业软件输出格式化的文本文件，但是格式复杂
    - 后处理通过求解器输出二进制文件，只能通过特定API接口读取，数据量大，格式复杂

* 是否需要进行数据清洗：  
   需要数据清洗：  
   - 针对前处理文件提取关键词进行模型检查、校核工作
   - 针对后处理结果提取关键值、曲线等输出信息，用于评估结构性能
   - 目前上述工作需要专业的有限元软件，正在尝试通过自主开发工具进行关键数据的清洗工作